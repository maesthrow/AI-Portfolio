# Техническое задание: Переработка RAG-сервиса rag-api-new

## Цели проекта

- **Устранение системных ошибок в ответах агента.** Действующая версия RAG-агента страдает от ряда проблем: добавление ненужных завершающих фраз об отсутствии данных[1], чрезмерно формальный стиль речи[2], утечка технических подробностей в ответ (внутренние идентификаторы, confidence)[3], неполнота перечислений фактов[4] и включение нерелевантной информации[5]. Необходимо исправить эти дефекты системно, а не точечными костылями.
- **Повышение полноты, точности и естественности ответов.** Агент должен выдавать все релевантные факты по запросу пользователя (в разумных пределах), не теряя информацию и не добавляя лишнего. Стиль ответов – более разговорный и дружественный (без бюрократических формулировок), формат – удобочитаемый (списки, структурирование).
- **Внедрение современной архитектуры Graph-RAG.** Основная стратегия поиска фактов должна сместиться к **Graph-RAG** – то есть использованием графа знаний портфолио и точных графовых запросов, где это применимо. Это позволит получать факты напрямую по связям, без потерь и без необходимости сложного ранжирования[6][7]. Классический текстовый RAG (ChromaDB + гибридный поиск) остаётся в качестве резервного варианта для общих вопросов или при недостатке структурированных данных[8].
- **Соблюдение принципов Clean Architecture.** Переработка должна улучшить внутреннюю архитектуру: каждый компонент выполняет свою роль (SOLID), минимизация избыточности (DRY) и усложнения (KISS), четкое разделение уровней. Существующие модули сохраняются, если они логически оправданы, но могут быть рефакторены для лучшей модульности и тестируемости. Новые компоненты (GraphSchema, инструменты и пр.) интегрируются без нарушений текущих слоёв.

**Общая концепция решения:** При поступлении запроса система сначала определяет его тип (намерение) и ключевые сущности. Если запрос фактический и может быть покрыт графом знаний (например, "достижения на проекте X"), агент воспользуется **graph_query_tool** – инструментом для прямого извлечения фактов из графа (например, всех достижений проекта)[9][10]. Агент получит структурированный результат и сформирует ответ, перечисляя все найденные факты в понятном формате. Если же запрос общий или граф не применим, выполняется стандартный гибридный поиск по векторной базе (ChromaDB) и BM25. Предусмотрен **fallback**: при отсутствии результатов в графе или низкой уверенности, система автоматически переключится на традиционный RAG-поиск. На этапе генерации ответа действует новый форматтер, управляющий стилем вывода согласно шаблону и **style_hint** (например, списки — маркерованные, без технических ссылок). Механизм памяти диалога (история) улучшен: строгий детектор **follow-up** решает, когда включать контекст предыдущих вопросов, предотвращая перенос неотносящихся фактов в новые ответы. Ниже требования разбиты на эпики (модульные блоки) с описанием цели, доработок, интерфейсов и критериев приёмки.

## Эпик 1 — Архитектура Graph-RAG и инструмент графового поиска

**Цели и обоснование:** Реализовать представление данных портфолио в виде графа знаний и предоставить агенту инструмент для точных структурированных запросов к этому графу. Это решение гарантирует полноту выдачи фактов по связанным сущностям и устраняет зависимость от неидеального ранжирования текста. Например, запрос «какие достижения на проекте X» должен приводить к извлечению *всех* узлов-достижений, связанных с проектом X, независимо от формулировки вопроса[9][11]. В текущей системе один из пунктов мог теряться из-за порога релевантности или агрессивной фильтрации[12]; с Graph-RAG этого не случится – отношения “проект–достижение” заданы явно. Graph-RAG станет основной стратегией получения фактов по портфолио, повышая точность и прозрачность ответов[7].

**Доработки по архитектуре и коду:** Необходимо ввести новый слой данных – **граф знаний портфолио** – и связать его с агентом через специальный инструмент запроса.

- **GraphSchema (модель графа):** разработать схему графа, описывающую сущности и связи в данных портфолио. Узлы графа: Person (профиль Дмитрия), Company (компания/организация), Project, Achievement, Technology, Education и т.д. Ребра графа отражают отношения: например, Person -[WORKED_AT]-> Company, Company -[HAS_PROJECT]-> Project, Project -[HAS_ACHIEVEMENT]-> Achievement, Project -[USES_TECH]-> Technology, Person -[HAS_SKILL]-> Technology и т.п.[13][6]. Каждой сущности назначается уникальный ключ (например, slug или ID) для однозначной адресации в запросах.
- **Хранилище графа:** выбрать механизм хранения и запросов. Учитывая ограниченный объём данных портфолио, можно реализовать граф в памяти (например, с помощью библиотеки типа NetworkX, или через простые структуры словарей/списков связей). Допустимо использовать и внешнее граф-хранилище (Neo4j, мемори-Graph DB), но это увеличит сложность; предпочтительно начать с in-memory реализации для KISS-принципа. Данные графа должны заполняться/обновляться при индексации портфолио: модифицировать пайплайн ingest так, чтобы после сохранения документов в БД и векторного индекса происходило добавление узлов и связей в граф. Например, при добавлении нового проекта через /api/v1/ingest/batch создаётся узел Project со slug, связывается с Company и Profile, достижения проекта добавляются как узлы Achievement, связанные с Project, и т.д. (при повторном инжесте возможна очистка/перестроение графа, кэш EntityRegistry тоже сбрасывается[14][15]).
- **Инструмент graph_query_tool:** реализовать новый инструмент агента (в agent/tools.py и/или agent/graph.py), который принимает структурированный запрос (намерение + сущность) и выполняет обращение к графу. Инструмент может быть оформлен как функция или класс, предоставляющий метод query_graph(intent, entity_key). Внутри него зашиты предопределённые шаблоны запросов под ключевые типы намерений:
- *Пример:* Intent=ACHIEVEMENTS, Entity=ALOR_BROKER вызовет поиск узла проекта со slug "alor-broker" и выбор всех связанных узлов-достижений[11]. Псевдокод в терминах Cypher: MATCH (p:Project {slug:"alor-broker"})-[:HAS_ACHIEVEMENT]->(a:Achievement) RETURN a.
- Другой пример: Intent=RAG_USAGE + Entity=RAG (технология) – найти узел Technology "RAG" и вернуть связанные проекты: MATCH (t:Technology {key:"RAG"})<-[:USES_TECH]-(p:Project) RETURN p.
- **Выход инструмента:** структурированные данные: список найденных элементов (items) и, при необходимости, дополнительный контекст. Например, для достижений возвращается массив строк с описаниями достижений. Могут также возвращаться идентификаторы источников (sources) – например, ссылки на узлы проекта или IDs документов, степень уверенности (confidence) и флаг found. Формат результата оформляется в виде словаря/объекта **GraphQueryResult**. *Пример контракта:*

```json
graph_query_tool(intent="ACHIEVEMENTS", entity="alor-broker") -> {
    "items": [
        "Переписал код трёх сервисов под новый стек...",
        "Запустил сервис нотификаций для бэк-офиса и клиентов.",
        "Интегрировал сервис отправки сообщений в инфраструктуру компании."
    ],
    "found": True,
    "sources": ["project:alor-broker"],
    "confidence": 1.0
}
```

- Агент, получив такой результат, будет знать, что items содержит факты, требующие перечисления.
- Нужно обработать случаи, когда граф-запрос ничего не возвращает: инструмент должен устанавливать found=False или возвращать пустой список, чтобы агент понял – данных нет.
- **Интеграция Graph-RAG в агента:** модифицировать логику **планирования запроса** (Query Planning) и работы агента так, чтобы при наличии соответствующего намерения он вызывал graph_query_tool. В режиме streaming-агента (ReAct loop) это означает, что после анализа вопроса агент делает шаг Action: graph_query_tool вместо текстового поиска. В синхронном режиме (/ask) – можно напрямую определить, что запрос требует графового поиска, и использовать результат для генерации ответа.
- Следует убедиться, что новый инструмент не нарушает стриминг: агент по-прежнему генерирует ответ токен-за-токеном, просто в качествеObservation получает не готовый текст из поиска, а структурированный вывод графа[16][7]. В остальном его работа не меняется.
- Реализация должна быть **под фичефлагом**: например, флаг agent_fact_tool=true уже предусмотрен для переключения агента на новый инструмент вместо старого[17]. Возможна установка отдельного флага graph_rag_enabled, либо переиспользовать agent_fact_tool для включения графового инструмента. При флаге false агент должен работать по старой схеме (через portfolio_rag_tool, т.е. обычный поиск и готовый текст)[18][19].
- Также потребуется обновить **prompt шаблон агента**: он должен учитывать, что теперь инструмент возвращает структурированные факты. Агенту в системном сообщении или примерах надо указать, чтобы он **использовал только эти факты при формировании ответа** и не додумывал лишнего. (Подробнее форматирование ответа – в эпике 3.)
- **Fallback на гибридный поиск:** Внедрение Graph-RAG не должно сломать способность отвечать на общие вопросы. Если запрос не подходит под шаблоны графовых запросов (например, очень общий или требует связной рассказ), или если graph_query_tool вернул пустой результат, система должна автоматически перейти к стандартному процессу RAG:
- В контексте /ask: функция ответа проверяет found или уверенность. Если граф не дал результатов, выполняется обычный portfolio_search с dense+BM25 поиском по документам.
- В агенте: если graph_query_tool не нашёл ничего (или, гипотетически, агент решил, что нужно дополнительный поиск), он может вызвать и текстовый поиск. Однако, предпочтительно, чтобы QueryPlan решал заранее, нужен ли граф или текст.
- Критерии перехода можно настроить через порог confidence (min_confidence_for_answer): если уверенность ответа ниже заданной, делаем резервный поиск[20][21].
- **ChromaDB** и связанный гибридный поиск остаются частью системы, но теперь в первую очередь как резерв и для вопросов, которые не сводятся к конкретным фактам портфолио. Архитектурно, модуль rag/retrieval.py продолжает работать, но будет вызываться либо после графового шага (если он не дал результата), либо напрямую для GENERAL запросов.

**Вход/выход и взаимодействие:** Компоненты Graph-RAG взаимодействуют следующим образом (новый **контракт**): 1. **QueryPlan** (см. Эпик 2) анализирует вопрос. Если намерение подходит для графа и определена сущность, формируется запрос: intent + entity_key. 2. **GraphQueryTool** получает этот запрос, выполняет поиск по графовым данным и возвращает объект GraphQueryResult с найденными фактами. 3. **Agent** (LangChain/LangGraph) принимает результат инструмента. Если items не пуст, агент понимает, что нужно перечислить эти факты пользователю. Агент составляет финальный ответ, опираясь *исключительно* на полученные факты, без произвольных дополнений. 4. Если GraphQueryResult.found=False (ничего не найдено), агент (или /ask хендлер) инициирует альтернативный поиск: вызывает обычный portfolio_search для обработки запроса через векторный индекс. Далее ответ генерируется по старой схеме на основе текстового контекста. 5. В обоих случаях, форматирование ответа контролируется шаблоном (эпик 3): например, наличие items в результате приведёт к формированию маркированного списка.

**Ограничения, фичефлаги и риски:** - Внедрение Graph-RAG следует проводить постепенно. Флаг agent_fact_tool (и/или новый graph_rag) по умолчанию отключён на production; его можно включать для тестирования. - Требуется миграция/реиндексacija данных для заполнения графа при первом развёртывании. Нужно обеспечить, что админ-методы перезагрузки данных вызывают перестроение графа (например, при DELETE /admin/collection + повторном ingest — граф синхронизируется). - Производительность: следить, чтобы графовые запросы были быстрыми. На объёмах портфолио (<1000 узлов) проблем не ожидается. Но если решим использовать внешний граф DB, нужен контроль задержек. - Следует убедиться, что при включенном Graph-RAG ответы корректны; в случае обнаружения отклонений всегда есть fallback на старый путь. - SOLID: Новый инструмент должен легко расширяться под другие отношения. Например, при появлении нового типа запроса (скажем, «в каких проектах работал в компании X») добавляется новый Intent и шаблон запроса, не ломая существующий код (Открытость/закрытость). - Документация: Обновить архитектурный документ, описав GraphSchema и примеры запросов.

**Критерии приёмки и тестовые кейсы:** - **Полнота фактов.** Для вопросов, предполагающих структурированные ответы, агент возвращает **все релевантные факты**: - Запрос: «Все достижения по проекту T2». Ожидается, что в ответе будут перечислены *все* достижения проекта T2 (например, N пунктов, соответствующих каждому достижению в базе), без пропусков. Никаких завершающих фраз об отсутствии других достижений быть не должно[12]. - Запрос: «Какие достижения на проекте АЛОР?» – в портфолио у Дмитрия их три[22]. Новая система должна вывести три пункта. Ранее выводился только один с фразой, что больше деталей нет[23]; это считается провалом теста. После внедрения Graph-RAG тест пройдёт, если агент стабильно выводит все три. - **Корректность отбора.** Агент не включает факты по несвязанным сущностям: - Запрос: «Где применял RAG?». Ответ должен содержать список проектов, где использована технология RAG – и **только их** (например, проект *t2* и *AI-Portfolio* согласно данным). В старой версии в ответ затесался проект СКИО, не относящийся к RAG[24]. Критерий выполнения – отсутствие упоминания СКИО (или любых проектов без RAG) в новом ответе. - Аналогично, запрос «Какие языки программирования знает?» – ожидается перечисление языков (Python, C++ и т.д.). Недопустимо, чтобы в списке оказались фреймворки или технологии, ошибочно принятые за языки. В тестах проверяется, что агент не смешивает категории (например, не называет Django "языком")[25]. - **Сценарии fallback:** - Искусственно смоделировать ситуацию, когда граф не выдаёт результат (например, спросить факт, которого точно нет в портфолио). Тест пройден, если система автоматически переходит к общему поиску и возвращает корректный ответ "нет информации" без сбоев. - Отключение фичефлага Graph-RAG: при agent_fact_tool=false либо соответствующем параметре, поведение /ask и агента остаётся как в старой версии (для регрессии). Например, все вышеупомянутые кейсы при отключённом флаге воспроизводят старое поведение (не лучше, но и не сломано). - **Покрытие тестами:** Юнит-тест на graph_query_tool: подставляя разные intent/entity (в том числе несуществующие), убеждаемся, что возвращается правильная структура данных. Интеграционный тест: полный цикл для типового вопроса (например, про достижения) – сравнивается список на выходе с эталоном из БД.

## Эпик 2 — Планирование запросов и гибридный поиск (Intent + Entity aware retrieval)

**Цели и обоснование:** Улучшить «понимание» вопросов системой для выбора оптимального способа поиска. Каждому запросу должен соответствовать план: какие типы данных искать, какие фильтры применить, какой инструмент (граф или текстовый поиск) использовать. Это решает проблемы неточного поиска и ранжирования, которые приводили к неполноте или шуму. В старой системе ретривер мог возвращать лишние документы (напр. проект СКИО при вопросе про RAG) из-за того, что фильтрация по сущности сработала нестрого[26][27]. Или наоборот – пропускать данные, если вопрос упомянут не точно (напр. алиас проекта не распознан, и Strict-фильтр отсеял нужные документы)[28][29]. Чтобы это решить, вводится слой **Intent & Entity-aware QueryPlan**.

**Конкретные изменения:** - **Определение намерения (Intent):** реализовать классификацию входного вопроса на предопределённые категории. Намерение – это тип запроса, отражающий, что хочет пользователь: - Например: ACHIEVEMENTS (спросить о достижениях проекта/компании), CURRENT_JOB (о текущем месте работы/позиции), LANGUAGES (о языках программирования), RAG_USAGE (где использована технология RAG или другая технология), CONTACTS (контактные данные), PROJECT_DETAILS (детали конкретного проекта), GENERAL (общий вопрос/разговорный) и т.д. Перечень намерений взять из анализа частых запросов; из backlog: Achievements, CurrentJob, Languages, RAG_Usage, Contacts, Project_Details, General[30]. - Классификатор Intent может быть реализован простыми правилами/ключевыми словами (например, слова "достижения", "достиг" -> ACHIEVEMENTS; "где работ" -> CURRENT_JOB; перечисление проектов -> возможно RAG_USAGE или LANGUAGES в контексте технологий). В перспективе можно обучить небольшую ML-модель или использовать LLM для определения Intent, но на первом этапе достаточно фиксированных правил на основе слов и структуры вопроса. - Код: добавить модуль rag/query_plan.py с логикой определения Intent по тексту вопроса[31].

- **Извлечение сущностей из вопроса:** параллельно определить, какие конкретно объекты из портфолио упомянуты:
- Распознавать названия проектов, компаний, имена людей, названия технологий, годы и т.д. Например, из вопроса "проект АЛОР" извлекается сущность Project со значением "АЛОР" (который в базе соответствует "АЛОР Брокер")[28]. Из "где применял RAG" – сущность Technology "RAG".
- Этот функционал выносим в rag/entities.py (если нет, создать)[31][32]. Использовать простое правило: поиск совпадений с известными названиями из EntityRegistry (см. эпик 4) или, при необходимости, NLP-библиотеку для именованных сущностей. Важно учитывать регистр, транслитерацию (например, "AI Portfolio" vs "AI-Portfolio"), возможные сокращения (как "СКИО").
- Результат – список найденных сущностей с типами и идентификаторами (или алиасами). Если сущность однозначно определена – отмечаем это.
- **Формирование QueryPlan:** на основе Intent и извлечённых Entities строится структура запроса, которая будет передана механизму поиска:
- Задаётся **набор типов документов (allowed_types)**, релевантных запросу. Например, для Intent=ACHIEVEMENTS ищем документы типа achievement (и связанные project/experience, если нужно контекст)[33]. Для CURRENT_JOB – только раздел профиля/опыта. Для LANGUAGES – раздел навыков/технологий. Это ограничение сократит шум от нерелевантных разделов.
- Определяется **политика по сущностям**: entity_policy. Если имеется точно одна идентифицированная сущность (e.g. конкретный проект по имени) – можно применить режим STRICT, т.е. ограничить поиск только документами, привязанными к этой сущности[34]. Если сущностей несколько или неуверенно – BOOST (учитывать их как фактор ранжирования, но не отсекая полностью другие результаты)[35]. Если сущностей нет – NONE (обычный поиск по всему).
    - Правило: **1 кандидат = Strict, >1 или не уверены = Boost.** Например, для вопроса "АЛОР проект" если EntityRegistry даёт один проект "alor-broker", применяем Strict по project_id; если пользователь упомянул только "Дмитрий" (сам профиль) или вообще ничего конкретного – Strict не применяется.
- Устанавливаются параметры выборки документов: сколько брать из dense (к_embedding), сколько из BM25 (k_bm), сколько после rerank (k_final). Эти числа могут зависеть от намерения; напр., для списка достижений можно взять больше документов (или напрямую items из графа), а для точечного вопроса – меньше. В QueryPlan фиксируем эти настройки.
- **Выбор инструмента:** QueryPlan решает, будет ли использован Graph-RAG или текстовый RAG:
    - Если Intent принадлежит к категории структурированных (ACHIEVEMENTS, CONTACTS, и пр.) **и** успешно определена сущность (или несколько) – предпочтительно пойти через graph_query_tool. План помечается как use_graph=True (или прямо указывает tool).
    - Если Intent = GENERAL или данные сильно размазаны (нет явной структуры) – используем стандартный векторный поиск (use_graph=False).
    - Компромиссные случаи: например, Intent=RAG_USAGE, Entity=RAG (tech) – если мы занесли технологии в граф, можем выполнить граф-запрос (получить проекты по технологии RAG). Если такой граф не реализован, то придётся сделать текстовый поиск, но с фильтром по tech=RAG. В спецификации закладываем возможность обоих вариантов. В идеале – реализовать узлы Technology и связи с проектами, тогда graph_query_tool покрывает и этот случай.
    - QueryPlan также содержит критерии fallback: например, min_confidence_for_answer – если суммарная уверенность найденного низка, или items пусты, план предусматривает альтернативный путь[20].
- Реализовать функцию portfolio_search(query) в модуле rag/search.py которая:
    1. Генерирует QueryPlan (Intent + Entities → Plan).
    1. Если use_graph: вызывает GraphQueryTool и получает GraphQueryResult.
    1. Если результат found=True и confidence нормальный, передаёт его дальше (в /ask или агент).
    1. Если нет (пусто/недостаточно) – логирует и переключается на use_graph=False путь (fallback).
    1. Если use_graph=False: выполняет гибридный поиск:
    1. Фильтрует/бустит кандидатов согласно плану (типы документов, сущности). Возможно, модифицирует существующие функции: в retrieval.py и evidence.py встроить использование allowed_types и entity_policy из плана[36][37].
    1. Получает k_dense + k_bm кандидатов, применяет Cross-Encoder rerank (если настроен) и выбирает топ-k_final.
    1. Результат оформляет в структуру (например, класс SearchResult) с полями: evidence_snippets (текстовые отрывки), sources (идентификаторы документов), confidence (например, средний скоре) и, при наличии, items. *Примечание:* если параллельно внедрены **Atomic docs** (эпик B из backlog), то при вопросах-списках (намерение ACHIEVEMENTS и т.п.) в top-кандидатах окажутся отдельные документы-элементы. Их можно собрать как items. В сочетании с Graph-RAG это может служить вторым источником полноты – однако, при активном графе, atomic docs в vectors не критичны.
    1. Если ничего не найдено, устанавливает found=False.
    1. Возвращает объект SearchResult либо GraphQueryResult – в общем, структуру, понятную следующему этапу (агенту или форматтеру). В конечном счёте, /ask может сразу сформировать текст из этого результата (в простых случаях), либо в агенте результат пойдёт в prompt.
- Внедрить включение этой логики по фичефлагу RAG_ROUTER_V2 (Route v2)[20][38]. Если флаг выключен – portfolio_search() либо не используется, либо работает в режиме совместимости (например, просто вызывает старый flow). Флаг хранится в settings.py[39].
- **Правки точек входа:**
- Эндпоинт /api/v1/ask теперь должен использовать новый планировщик. Ранее он мог напрямую вызывать что-то вроде core.portfolio_rag_answer(query). Нужно изменить на: сформировать SearchResult через portfolio_search(), затем сгенерировать ответ (возможно, вызовом LLM с готовым контекстом). Если SearchResult содержит items, можно сразу промптить LLM с просьбой перечислить их (или даже отформатировать самостоятельно, но лучше доверить LLM с инструкцией).
- Агент (чат-стрим /agent/chat/stream): если включён agent_fact_tool, Agent при вопросе должен вызывать не portfolio_rag_tool (который раньше возвращал текст), а новый инструмент. В рамках этого эпика, мы подготавливаем базу для такого инструмента: portfolio_search_tool(question), который под капотом вызывает ту же portfolio_search() и возвращает структуру. (Реализация самого инструмента и обработка вывода — в эпике 4/D). Здесь важно, что search.py функции переиспользуются для агента тоже (DRY: один механизм поиска и для sync, и для async).
- Обновить app/rag/core.py и связанные модули, чтобы использовать QueryPlan: см. backlog PR-04, перевод /ask на новый search->answer pipeline[40].

**Интерфейсы и данные на выходе:**<br>После выполнения portfolio_search() имеем унифицированный результат. Предлагается ввести Pydantic-схему SearchResult (в schemas/):

```python
class SearchResult(BaseModel):
    query: str
    intent: str
    entities: List[Entity]  # e.g. Entity(name="ALOR", type="Project", key="alor-broker")
    items: Optional[List[str]] = None      # structured facts (e.g. list of achievements)
    evidence: Optional[List[str]] = None   # textual evidence snippets
    sources: Optional[List[str]] = None    # document or node identifiers
    confidence: Optional[float] = None
    found: bool
}
```

Аналогично для GraphQueryResult можно унаследовать от SearchResult или включить в него (раз items уже есть). При вызове через /ask, этот результат затем преобразуется в конечный ответ (см. форматирование). При использовании в агенте, он будет сконвертирован в строку наблюдения для LLM. Важный контракт: **если items не пуст, они должны быть представлены агенту как перечисление фактов, а не как один склеенный текст**, иначе снова возникнет риск потери части (это обеспечит эпик 3/D с новым шаблоном ответа).

**Ограничения и фолбэк:** - Точность определения Intent/Entity критически влияет на последующий поиск. Необходимо тщательно протестировать правила. Если Intent определён неправильно, может неверно примениться фильтр. Поэтому, если уверенность в классификации низкая, возможно, стоит пометить как GENERAL (т.е. перестраховаться в сторону полноты). - Entity extraction должна учитывать падежи и склонения русского языка. Возможно, понадобится привести вопрос к именительному или иметь словарь склонений для проектов/компаний. - **Disambiguation:** В случае многозначности имен (например, проект и технология могут называться схоже) – пока можно выбирать по приоритету намерения (если Intent про технологии – брать технологию, и наоборот). Более сложное разрешение вне рамок первой версии. - Все новые параметры (Intent схемы, кол-во документов, пороги) сделать настраиваемыми (через settings.py) для облегчения калибровки без изменения кода.

**Критерии приёмки:** - **Правильный выбор инструмента:** - Вопрос: «Где сейчас работает Дмитрий?» Должен распознаться Intent=CURRENT_JOB, Entity=Dmitry (Profile). План должен ограничить поиск профилем/опытом. Результат: либо граф (узел Person->Company с пометкой текущего?), либо поиск по документам профиля. Ответ не должен содержать длинных рассуждений; если данных нет, агент скажет коротко, что информации нет (и *не* станет добавлять ничего лишнего). Тест считается пройденным, если ответ чётко отражает отсутствие текущего места работы, без формальных оговорок. - Вопрос: «Где применял RAG?» → Intent=RAG_USAGE, Entity=RAG. Система должна либо выполнить графовый запрос по технологии RAG, либо текстовый поиск с фильтром tech=RAG. В любом случае, проекты без RAG не должны попасть. В ручном тесте проверяется, что ответ содержит только проекты с RAG (например, "Проекты, где применялся RAG: **AI-Portfolio**, **t2**.") и не упоминает СКИО или других посторонних[24]. - Вопрос: «Какие языки программирования знает?» → Intent=LANGUAGES. Entity может не быть (или быть "ProgrammingLanguages" как категория). План должен вытаскивать список языков из профиля/резюме. Проверка: в ответе перечисляются языки, и не затесались инструменты, которые не являются языками (напрямую проверяется, что слова вроде "Django", "PyTest" отсутствуют в списке). - Вопрос: «Расскажи о проектах в EPAM.» → Intent возможно PROJECT_DETAILS или GENERAL (требуется анализ), Entities: Company="EPAM". План: если Company найден, можно применить Strict по company (все проекты этой компании). Ответ должен фокусироваться на проектах EPAM, и не уходить в другие компании. - **Entity Resolution тесты:** - «про проект АЛОР» – ранее система могла спутать с компанией Alor+ или не понять, и возвращала неполные данные[28]. Теперь: EntityExtractor находит Project "ALOR_BROKER". Plan ставит Strict по project. Проверка: выходной результат содержит достижения именно проекта АЛОР Брокер, все три пункта. - Попробовать вариации: «проект Alor», «ALOR», «Алор» (разные регистры, язык) – во всех случаях EntityRegistry должен мапить на нужный slug. Тест успешен, если ответ каждый раз полный и про тот же проект. - Случай неизвестной сущности: «достижения проекта XYZ» (XYZ нет в базе) – EntityExtractor не найдёт, Plan пойдёт без Strict. В этом случае либо ничего не найдётся (и ответ корректно "нет информации"), либо попадёт что-то общее. Главное – не упомянуть чего-то несвязного. Приёмочный критерий: в ответе либо честно "нет такого проекта", либо пустой ответ без ошибок. - **Регрессионные сценарии:** При отключении фич (Router v2 = false), старый механизм работает. Убедиться, что базовые запросы ("кто ты такой?", "что такое RAG?") возвращают ответы как прежде (т.е. Router v1 fallback). - **Внутренние метрики:** После внедрения entity-aware retrieval должна снизиться доля ошибок типа "нерелевантные включения" и "пропущенные факты". Можно провести офлайн-оценку: взять набор вопросов, сравнить ответы до/после. Успехом будет, если ни в одном из тестовых вопросов система не потеряла факт, который был раньше, и устранила хотя бы те ранее зафиксированные ошибки (ALOR, RAG+СКИО и пр.).

## Эпик 3 — Форматирование ответа и естественный язык

**Цели и обоснование:** Обеспечить структурированный, чистый и естественный вывод ответов агента. Пользователь должен получать информацию в удобном виде: списки – в виде списков, текст – связный и дружелюбный. Не должно быть внутренних технических артефактов (номеров ссылок, confidence) и лишних фраз, которые пользователь не запрашивал. Данный эпик отвечает на выявленные проблемы: *«хвосты»* в ответах[1], *формальный тон*[2], *артефакты форматирования*[3]. Исправления должны быть сделаны через изменение шаблонов и пост-обработки формата, не ломая основной движок LLM.

**Конкретные доработки:** - **Маркированные списки для перечислений:** Если ответ предполагает перечисление нескольких однотипных фактов (проекты, достижения, технологии, языки и т.д.), выводить их в виде списка с маркерами -. - В существующей реализации агент иногда выводил список через запятую или смешанные форматы. Теперь вводится единый подход: **каждый элемент – с новой строки, с начальным дефисом (bullet)**[41][42]. Это требование нужно донести до модели либо на этапе формирования prompt, либо через пост-обработку. - **Реализация:** добавить поле или переменную стиля, указывающую формат вывода. Например, использовать уже упомянутое поле style_hint. При подготовке запроса LLM, если style_hint="LIST", добавить в системное сообщение инструкцию: *«Перечисли каждый найденный пункт с новой строки, начиная с дефиса»*[43][42]. Если style_hint="TEXT" (обычный ответ), такой инструкции не давать. - Это можно оформить через шаблонизатор: например, в prompt-шаблоне включить условный фрагмент: {% if style_hint == "LIST" %} ... инструкции ... {% endif %} (в зависимости от используемого шаблонизатора). - Код: в agent/formatter.py или новом модуле **format_renderer** прописать логику: анализирует SearchResult/GraphQueryResult. Если поле items не пустое и их больше одного – устанавливает style_hint="LIST". Также, возможно, если Intent относится к перечислениям (Achievements, Languages, Contacts etc.), тоже принудительно лист. - Либо, более явное решение: сам graph_query_tool может пометить в результате style_hint="LIST" (поскольку он «знает», что возвращает список фактов). Это флаг пройдёт через агент к форматтеру. - **Пост-обработка:** если по каким-то причинам модель всё же вывела элементы не с новой строки, можно на этапе выдачи клиенту поправить Markdown (но лучше добиться от модели сразу правильно). - Пример: для запроса про достижения ALOR, выход должен быть:

```markdown
- Переписал код трёх сервисов под новый стек.
- Запустил сервис нотификаций для бэк-офиса и клиентов.
- Интегрировал сервис отправки сообщений в инфраструктуру.
```

вместо одного пункта и текста "остальных нет" – пользователь увидит полный аккуратный список[44].

- **Удаление необоснованных уточнений:** Агент более **не должен сам дописывать** фразы типа "конкретных упоминаний больше не найдено" или "подробностей не обнаружено" в конце ответа[1]. Эти хвосты признаны шумовыми.
- Изменить соответствующий шаблон/логику: в prompt явно запретить фразы, указывающие на отсутствие информации, если об этом не спрашивали. Например, добавить правило: *"Если не нашёл информации сверх перечисленного – не упоминай об этом."*
- Более того, если инструмент found=False (ничего не найдено вообще), агент должен просто кратко ответить отрицательно, **без перечисления чего нет**[45]. Например: *"Такой информации нет в портфолио."* – и точка. Не нужно добавлять детальные списки чего не нашли.
- Технически, можно поставить проверку флага found после поиска: если False, формировать заранее заготовленный ответ-шаблон (возможно, даже без обращения к LLM, чтобы не было ризика "додумать"). Но допустимо и через LLM, но с чёткой инструкцией: "ответь одной фразой, что данных нет".
- В portfolio_search_tool, если обнаружено, что по запросу ничего нет, можно установить поле no_data=True и шаблон это обработает.
- **Скрытие технических ссылок и метаданных:** Убрать из пользовательского ответа все служебные обозначения:
- **Ссылки [1], [2]...**: В старой версии ответы содержали сноски с идентификаторами (например, [1] – achievement:experience_project:5:...)[46]. Они не информативны для пользователя. Решение: **не включать эти ссылки в prompt на генерацию ответа**.
    - Ранее, вероятно, формировался контекст с пометками источников, и модель их повторяла. Теперь, на этапе формата, **источники либо не передаются модели вовсе, либо преобразуются в читабельный вид**.
    - Минимально: на уровне format_renderer удалить/очистить все метки вида [n] из контекста перед отдачей в LLM.
    - Лучше: не включать ссылки в текст подсказки. Например, если evidence были "… (источник: Project X)", можно оставить только сам текст без "(источник…)" части.
    - Если есть потребность показать источник, реализовать маппинг: вместо achievement:experience_project:5:9468... подставить человекочитаемое название (например, "[1]" -> "Проект *Aston Neural Networks*"). Но пока, согласно ТЗ, достаточно скрыть ссылки совсем[47][48].
- **Confidence:** Удалить упоминания confidence. Они могли проникать из структуры SearchResult в финальный ответ (например, модель видела (confidence: 0.0005) и включала это)[49]. Решение: вообще нигде в prompt/контексте для LLM не упоминать слово "confidence" и цифры. Этот параметр только для внутренних решений (fallback, сортировка).
- В коде: убедиться, что на этапе сборки prompt (где-то в agent/prompt.py или аналогичном) не вставляются строки с такими метаданными. Если используется LangChain's SourceDocuments with citations, нужно override формат.
- **Настройка стиля ответа:** Смягчить тон, сделать его более разговорным, если соответствует контексту (портфолио – достаточно неформальная обстановка).
- В имеющемся примере, модель начинала ответ с канцеляризмов: "На данный момент достоверной информации нет..."[2]. Надо добиться более человеческого изложения.
- Способ: пересмотреть системное сообщение и примеры для агента. Возможно, в промпте были шаблоны научного стиля, их нужно убрать[50]. Добавить, что агент общается от первого лица Дмитрия, дружелюбно и просто. Можно указать, что допустимо обращаться на "ты" (если выбрана такая стилистика для сайта), либо на "вы" но в простом тоне – решается с заказчиком стиля.
- SOLID: вынести стилистические настройки в конфиг (например, style_tone = friendly/formal) на случай, если понадобится поменять. Но по заданию – сделать "технический, промышленный стиль"? Нет, это про сам документ. Для агента – скорее дружелюбный стиль ассистента.
- **Пример обновлённого тона:** Вопрос: "Где сейчас работает Дмитрий?" Ответ мог бы быть: "В портфолио нет информации о текущем месте работы Дмитрия." – лаконично, без формальных вводных. Или на "ты": "В моём портфолио сейчас нет информации, где я работаю на данный момент." Это уже предмет fine-tuning prompt.
- **Компоненты форматирования:**
- Если вводится отдельный модуль **FormatRenderer**, он будет отвечать за преобразование SearchResult + style_hint в финальный текст. Фактически, он формирует prompt для LLM и может делать пост-обработку вывода (например, убедиться, что модель начала каждый пункт с "- ").
- Шаблон ответа (prompt) — это, возможно, JSON или Markdown примеры, как агент должен отвечать. Например, можем передавать в LLM что-то вроде:

```text
Контекст:
1. Переписал код трёх сервисов...
2. Запустил сервис нотификаций...
3. Интегрировал сервис отправки...
Вопрос: Какие достижения на проекте ALOR?
Инструкция: Перечисли каждый пункт списка с новой строки, начиная с дефиса, без лишних комментариев.
Ответ:
- Переписал код трёх сервисов...
- Запустил сервис нотификаций...
- Интегрировал сервис отправки...
```

- Такой подход явно направит модель. Детали реализации могут отличаться, но суть – предоставить LLM уже структурированные данные и чёткую инструкцию по формату.
- **Привязка к style_hint:** убедиться, что style_hint передается через все слои. Например, добавить поле в SearchResult (или в контекст, передаваемый в агент). Если используем LangChain, можно хранить его в AgentAssistant memory or context and refer in the prompt.

**Ограничения и допущения:** - Не перестараться с неформальностью: ответы всё же должны оставаться технически корректными. Избегать жаргона или излишней разговорности, если это не соответствует образу. - Длина списка: если найдено очень много элементов (например, технологий десятки), выводить все может быть громоздко. Здесь задействуем параметр rag_list_max_items[51]. Например, если >20 элементов, можно вывести 20 и приписать "и др." либо сгруппировать. Но порог и поведение уточнить. ВAcceptance-тестах можно заложить: при запросе "какие технологии использовал?" выводится не более 15, но охватываются основные – проверяется вручную, что ничего критичного не опущено. - Многоуровневые списки: маловероятно, но если нужно, пока ограничимся одноуровневыми bullets. - Английский vs русский: В портфолио могут быть названия проектов/техник на английском. Форматирование не зависит от языка, но стиль (на "ты" или "вы") – учитывать. Возможно, сделать настройку, что если вопрос задан на русском, отвечать на русском (скорее всего), а если на английском, отвечать на английском. Но это вне текущих требований, концентрируемся на русском UX.

**Критерии приёмки:** - **Отсутствие артефактов:** Ни в одном ответе не появляются квадратные скобки с тех. идентификаторами или confidence: - Тест: вопрос про любой проект, где раньше отвечало с [1][2] – убедиться, что теперь ответ либо вообще без сносок, либо с заменёнными ссылками (например, название проектов упоминается просто текстом). Проверка по строке: символ [ не должен появляться в ответе, кроме как часть грамматического предложения. - Вопрос про векторные БД (как в примере) – раньше было "(confidence: 0.x)" прямо в тексте[49]. Теперь этого не должно быть. - **Правильное форматирование списков:** - Тестовые вопросы, нацеленные на список: - «Перечисли все достижения в проекте F3.» Результат должен быть в формате маркированного списка: несколько строк, каждая начинается с "- ". Визуально проверяется, что это именно Markdown-список (можно рендерить HTML и убедиться). - «Какие технологии использованы в проекте AI-Portfolio?» – тоже список технологий с маркерами. - «Какие языки программирования знает?» – список языков. - Непрерывный текст в этих случаях считается провалом. Также провал, если модель сделала список, но без маркеров или пронумеровала (если не просили нумерованный). - **Удаление хвостов:** - Пример: «Какие ML-проекты у тебя были?» – раньше: агент перечислял проекты, а потом дописывал "Других ML-проектов не обнаружено"[1]. Теперь: ответ должен ограничиться только перечислением найденных ML-проектов. Если их, скажем, 3, то 3 пункта и всё, без заключительных фраз. Тест считается пройденным, если в ответе нет ни одной фразы отрицания/отсутствия, кроме случаев, когда вопрос *прямо* спрашивает, есть ли что-то или нет. - Аналогично, любые ответы не должны содержать шаблонных отговорок вроде "на данный момент информации нет" *в дополнение* к содержательной части. Либо содержательная часть, либо короткое отсутствие – но не вместе. - **Естественность стиля:** - Выполнить оценку тона на нескольких вопросах: - «Где сейчас работает Дмитрий?» – убедиться, что ответ не начинается с канцеляризма. Хороший признак – отсутствие фразы "На данный момент достоверной информации...". Лучше: "В портфолио нет сведений о текущем месте работы Дмитрия." Проверить это на выдаче. - «Привет, чем ты занимаешься?» (болтовня) – агент должен ответить от первого лица кратко, без перегруженных формулировок. - Отдельно проследить, что при style_hint="LIST" модель не ломает склонения. Например, начал ответ: "- Переписал код... - Запустил..." – здесь отсутствие подлежащего в каждой фразе нормально (стилистически в списке можно так). Если же модель пытается строить цельные предложения, тоже приемлемо, но важно единообразие. - **Компонентное тестирование:** - Проверить, что функция/класс FormatRenderer корректно преобразует входные данные. Можно замокать LLM: подставить фиксированные items и проверить, что формируется правильный Markdown. - Проверить, что при разных сочетаниях полей SearchResult (только evidence без items, только items, и то и другое) – форматтер выдаёт ожидаемый prompt/инструкции. - **Безопасность изменений:** Убедиться, что изменения форматирования не влияют на API-формат ответов (кроме улучшения читаемости). Например, если фронтенд ожидал HTML или MD, он продолжит получать Markdown. Фронтенд не должен быть затронут, кроме как перестанут приходить лишние символы (что хорошо). - **A/B тестирование:** Возможно, на стадии вализации вывести новые ответы на небольшой процент запросов и собрать обратную связь – субъективная метрика "естественности" должна повыситься. Успехом считается, если пользователи/тестеры отмечают ответы как более понятные и дружелюбные.

## Эпик 4 — Реестр сущностей и единая схема данных

**Цели и обоснование:** Ввести централизованный **EntityRegistry** для управления именами проектов, компаний, технологий и прочих ключевых сущностей. Это обеспечит согласованность между тем, как данные хранятся/индексируются, и тем, как пользователь о них спрашивает. С помощью реестра алиасов агент сможет правильно сопоставлять пользовательские формулировки с внутренними идентификаторами. Без этого возникали проблемы: сокращённые названия не распознавались (например, "проект АЛОР" не связывался с "АЛОР БРОКЕР")[28][29], из-за чего Strict-фильтр мог отсечь нужные документы, дав неполный ответ.

**Новые компоненты и изменения:** - **EntityRegistry (реестр сущностей):** реализовать структуру (например, класс EntityRegistry в rag/entities.py), которая при старте или при индексации собирает все ключевые сущности портфолио и их возможные обозначения: - Для каждого проекта: основное название, варианты написания, аббревиатуры, связанные продукты. Например, проект "АЛОР Брокер" может иметь алиасы: "АЛОР", "ALOR", латиницей и кириллицей. Проект "t2" может быть и так понятно, но, допустим, "SKIO" может писаться как "СКИО". - Для компаний: полное название "EPAM Systems", краткое "EPAM". - Для технологий: например, "RAG" может быть в базе записано как "Retrieval-Augmented Generation" – стоит явно добавить алиас "RAG". - **Slug-ключи:** Каждой сущности присваивается *ключ (slug)*, используемый как уникальный идентификатор в системе (и в GraphSchema, и в документах). Registry мапит alias -> slug. Например, "АЛОР" -> "alor-broker" (project slug), "СКИО" -> "skio" (project slug), "RAG" -> "rag" (tech key), "Дмитрий" -> "dmitry" (profile id). - Это можно формировать автоматически при ingest: на этапе нормализации данных (indexing/normalizer.py) генерировать slug'и для проектов, компаний и т.д. (возможно, уже делается). Затем на основе метаданных коллекции Chroma построить словарь алиасов[52][53]. В Chroma метаданных, как видно, хранятся поля типа project_slug, company_slug – их можно извлечь, собрать уникальные названия. - Реестр должен иметь методы: find_project(name:str) -> slug or None, find_company(name:str) -> slug, find_entity(name:str) -> (type, slug), а также обратное: получить человекочитаемое имя по slug (для ссылок в ответе, если потребуется). - Кеширование: так как данные не меняются часто, можно держать Registry в памяти. Обновлять (или сбрасывать кеш) при реиндексации (в ingest endpoints это упомянуто: очистка кэша сущностей)[14][15].

- **Учет алиасов в поиске:** Изменить модуль entity extraction, чтобы он использовал реестр:
- При разборе вопроса, помимо прямого совпадения вопроса с текстом документов, делать lookup по реестру. Например, встречая слово "АЛОР", EntityRegistry.find_entity("алор") вернёт Project: alor-broker. Тогда extraction вернёт объект Entity(type="Project", name="АЛОР", slug="alor-broker").
- Если в вопросе несколько слов, могущих быть сущностями, проверять каждое. Например, "опыт в EPAM по Python" – тут и компания, и технология. Их оба можно извлечь.
- Если обнаружено несколько сущностей разных типов, QueryPlan может учесть и их (в примере, Intent может быть general, но Entities = {Company=EPAM, Tech=Python} – можно искать пересечение, но это сложнее; возможно игнорировать одну – в данном, скорее Python главное).
- **Disambiguation (снятие неоднозначности):** Если один алиас соответствует нескольким записям (маловероятно, но например "Oracle" может быть и компанией, и СУБД; "Python" – язык и змея 😊 но змея не в портфолио). Можно по Intent решить: если Intent про технологии, берем технологию, если про опыт – может компания.
- Если в реестре не найдено соответствие – extraction может попытаться частичное совпадение. Напр., "АЛОР" может найти "alor-broker" по началу. Но лучше прописать основные.
- **Единая схема ключей в данных:** Убедиться, что везде используется одна система идентификаторов:
- В Chroma документах поле doc_id содержит тип и числовой/UUID (например, project:12)[54]. Возможно, slug есть отдельным полем.
- В GraphSchema узлы тоже идентифицируются slug'ами (более человекочитабельно).
- EntityRegistry фактически связывает человекочитаемые названия и эти ключи.
- Нужно проверить, что Strict-фильтр в поиске может применяться как по slug, так и по числовому ID. Вероятно, лучше использовать slug/string IDs везде (Chroma позволяет хранить мета).
- Добавить в документы метаданные project_key, company_key, tech_key и т.д., чтобы фильтрация была удобной (backlog PR-02 указывает добавлять *_key поля для фильтрации)[55]. Если atomic docs уже внедрены, там тоже эти поля есть.
- Тогда, QueryPlan Strict просто подставляет фильтр where project_key = 'alor-broker' в запрос к Chroma или BM25.
- **Feature flag:** Явно флаг на EntityRegistry можно не делать (это внутренняя улучшалка). Но он косвенно связан с RAG_ROUTER_V2 и RAG_ATOMIC_DOCS. Можно сделать так: при флаге RAG_ROUTER_V2 мы используем EntityRegistry для фильтрации; при старом – может, нет. Но смысла отключать нет, т.к. реестр не мешает.
- Однако, если очень перестраховаться: сделать USE_ENTITY_REGISTRY flag. По умолчанию true, но можно выключить, тогда extraction берёт сущности только по старому способу (просто NER по тексту без алиасов).

**Ограничения:** - Надо поддерживать актуальность реестра при изменении данных. Если админ удалил или добавил проект, алиасы должны обновиться. В ingest/batch после оперций "delete/add" следует вызывать обновление EntityRegistry (или помечать кэш как грязный). - Возможен случай, что одно и то же название фигурирует в двух разных категориях. Например, проект "Oracle" и технология "Oracle". Если пользователь спросит "Oracle", что делать? В первую версию, можно ориентироваться на Intent или контекст (например, "работал в Oracle" vs "использовал Oracle"). Если неразрешимо, агент может уточнить вопрос. Но такое в рамках портфолио навряд ли. Просто отметить этот риск. - Все алиасы должны быть тщательно выписаны; можно привлечь самого Дмитрия для предоставления распространённых сокращений, или сгенерировать: для русского названия добавить английский вариант, и наоборот.

**Критерии приёмки:** - **Правильное распознавание сокращений:** - Вопрос, содержащий сокращённое название, приводит к тому же результату, что и вопрос с полным названием. Например: - "Что делал на проекте АЛОР?" vs "Что делал на проекте ALOR Брокер?" – оба должны давать информацию о проекте ALOR Брокер. Приёмка: сравнить ответы, убедиться, что первый не теряет деталей относительно второго. - "Опыт работы в EPAM?" vs "Опыт работы в EPAM Systems?" – ответы эквивалентны (оба про EPAM Systems). - "Какие достижения в T2?" (если проект T2 в базе называется просто "T2") – обрабатывается нормально. Или если проект "SKIO" написан кириллицей "СКИО" в вопросе – тоже успешно. - Если раньше какой-то из этих вариантов давал пустой или частичный ответ, теперь должен давать полный. Например, кейс с "АЛОР" был провальным ранее[28][29] – новая версия проходит его: все достижения найдены. - **Strict vs Boost поведение:** - Тест: Вопрос "Где применял RAG?" – технология "RAG" не была явно в старом реестре (допустим). Теперь мы добавили "RAG". EntityExtractor находит RAG как Tech, Intent=RAG_USAGE. Strict фильтр по tech_key="rag" применяется. Проверка: ни один проект без tech=rag не вернулся. Если хоть один лишний – тест не пройден. Ранее тут, вероятно, Strict не сработал и Boost позволил левые результаты[56][57]. - Тест: Вопрос "Какие проекты в компании EPAM?" – Entity=EPAM (Company), Intent, допустим, PROJECT_DETAILS. Strict по company_key="epam". Ответ – список проектов только EPAM. Проверить, что нет проектов из других мест. - Тест многозначности: если спросить "Расскажи про проект F3 на EPAM" (допустим, F3 не EPAMовский проект, а другой компании), extraction может найти Project F3 и Company EPAM. План: возможно, не Strict, а Boost (несколько Entities). Проверить, что ответ не перемешал несуществующие связки (в идеале, агент может сказать "проект F3 в EPAM не числится", но это сложно). Минимум – система не упадет, и либо выберет что-то одно, либо спросит уточнение. - **Внутреннее тестирование:** - Вызвать EntityRegistry методы напрямую: поиск по разным ключам (полный, часть слова, в разных регистрах). Убедиться, что находят нужное. - Проверить, что при добавлении нового проекта через ingest он появляется в Registry. - Симулировать отсутствие alias: временно убрать "АЛОР" из алиасов, задать вопрос – убедиться, что система в Strict не идёт, а с алиасом идёт Strict. То есть, показать, что добавление алиаса действительно меняет поведение (до – ответ неполный, после – полный). Это демонстрирует ценность Registry. - **Документация и поддерживаемость:** - В описании кода документировать словарь алиасов, чтобы в будущем можно было обновлять (например, если Дмитрий поменяет названия проектов или добавит). - Acceptance: обзор кодовой базы показвает отсутствие дублирования логики сопоставления имён: всё централизовано в EntityRegistry (DRY). Если нужно поменять alias – достаточно в одном месте.

## Эпик 5 — Механизм памяти диалога и follow-up

**Цели и обоснование:** Обновить систему ведения диалога так, чтобы **каждый вопрос пользователя обрабатывался в корректном контексте** – либо как независимый, либо как уточнение к предыдущему. Нужны строгие правила определения связности запросов, чтобы избежать *контаминации* контекста. В старой версии были случаи, когда предыдущие ответы «протаскивали» лишние детали: например, после вопроса про Python-опыт следующий вопрос про RAG был воспринят как связанный и привёл к добавлению неподходящей информации (СКИО)[27][58]. Новая память (Memory v2) должна устранять такие ошибки.

**Основные доработки:** - **Детектор продолжения диалога (follow-up):** Разработать функцию, которая решает, является ли текущий вопрос продолжением предыдущего обсуждения, или это новый независимый вопрос. - Критерии (правила): - Если в вопросе есть указательные местоимения или наречия, явно отсылающие к прошлому ответу: слова типа "этот", "тот", "там", или вопрос начинается с союза "а", "и" (например: "а какие там достижения?")[59][60] – это сильный признак follow-up, т.к. без предыдущего контекста непонятно, про что речь. - Если вопрос грамматически содержит явное упоминание новой сущности/темы (например название технологии, компании, другой сущности) и самодостаточен, то скорее всего это **новый топик**[58]. Например: вопрос содержит собственное имя или термин (как "RAG" в "Где применял RAG?") – он понятен вне контекста, хотя мог быть вызван предыдущим ответом, но можно ответить с нуля. - Если тип вопроса сменился (до этого спрашивали список, теперь про конкретное, или наоборот). - Реализация: создать модуль agent/followup.py с функцией is_follow_up(prev_user_msg, prev_agent_msg, new_user_msg) -> bool. Эта функция может использовать простые правила по началу строки и наличию ключевых слов. При True может также возвращать, к чему именно относится (например, сохранить идентификатор проекта из прошлого ответа, если "там" – это он). - Возможно, понадобится парсинг предыдущего ответа: например, если предыдущий вопрос был про проект X и агент перечислял достижения, а новый "а какие технологии там использовали?" – детектор должен не только сказать True (follow-up), но и извлечь, что "там" = проект X. Это продвинуто: можно хранить в памяти последний топик (например, в Memory summary хранить "Topic: Project X"). - Первоначально можно упростить: если вопрос содержит "там/в нём/её" и предыдущий ответ упоминал одну ярко выраженную сущность, подставить её. Иначе, просто считая follow-up без уточнения. - **Настройка правил:** Эти правила могут корректироваться. В Acceptance-тестах оцениваем, что никаких ложных follow-up (как с RAG->СКИО) не осталось[61][62].

- **Фильтрация контекста истории:** Когда вопрос признан follow-up, нам нужно подмешать в новый запрос информацию из прошлого – но **только релевантную**:
- Старый подход мог брать весь предыдущий ответ или summary, что иногда приносило шум. Теперь:
    - Если предыдущий ответ был списком проектов/фактов, а новый вопрос уточняет про один аспект, желательно вытянуть только тот аспект.
    - Как вариант, можно перед выполнением нового поиска отфильтровать предыдущие факты: напр., в примере Python->RAG, предыдущий ответ был про 5 проектов, но RAG касается только 2, значит, в новый поиск/контекст стоит взять только информацию о тех 2 проектах[63][64]. Либо вообще ничего не брать и заново найти по RAG (что даже лучше, т.к. новый QueryPlan с Entity=RAG сам найдёт).
    - Можно реализовать простое правило: *если предыдущий ответ был перечислением более N различных сущностей*, не включать его целиком при follow-up (потому что велик риск, что follow-up относится не ко всем, а к одному). N может быть 3 или 5[65].
    - Вместо этого, либо ничего не вставлять (полагаться на свежий поиск), либо попытаться сузить: например, если в предыдущем ответе перечислены проекты, а новый вопрос про технологии "там", то можно вытянуть из предыдущего только название того проекта, который "там" имеется в виду (например, последний упомянутый?). Это непросто автоматически.
    - Пока можно принять стратегию: **консервативный подход** – при follow-up подмешивать не весь предыдущий ответ, а либо summary (см. далее) либо ключевой идентификатор.
    - Реализация:
    - Хранить вместе с summary (или отдельно) так называемый *контекстный указатель* – например, last_topic_entity. Если определено, что предыдущий вопрос был про проект X, сохранить context_entity = project:alor-broker. Тогда при follow-up, если новый вопрос без явной сущности, можно предположить, что он про X, и использовать это.
    - Тогда, QueryPlan для follow-up может включать entity X дополнительно (как будто пользователь сам его упомянул). В примере "а какие там достижения?" детектор поймёт, что "там" = X (предыдущий проект), и заполнит Entities = {Project X}. Дальше обычный процесс: Intent=ACHIEVEMENTS, Entity X -> GraphQueryTool -> получить достижения X. Это наиболее точный способ (фактически, агент сам связал вопрос с контекстом без лишней информации).
    - Если реализовать context_entity сложно, минимально: follow-up = True -> добавляем summary (который содержит краткую информацию).
- **Summary memory v2:** Предусмотрено хранить сжатое резюме последних N обменов (feature agent_memory_v2)[66]. Уже указано: recent_turns и summary с ограничением длины[67][68].
    - Нужно внедрить обновление summary через каждые M ходов (напр. каждые 6, как в настройках)[69].
    - Но важно **качество суммирования**: возможно, следует суммаризовать диалог по темам. Например, если был разговор про одну тему, потом смена – старое summary не нужно. Продвинуться можно так: добавлять в summary метки тем или хранить несколько отдельных summaries по темам (это сложно).
    - В рамках ТЗ: сделать хотя бы так, что summary хранит ключевые факты, но перед использованием проверять релевантность.
    - В детектор follow-up можно встроить: если новый вопрос по другому Intent, не использовать summary. Или если summary слишком общая.
    - Implementation: agent/memory.py для Memory v2, хранящий self.summary (строка) и self.recent_turns (список последних N пар). Когда вызывается new turn:
    - Если follow-up = True: включаем либо summary, либо последние N (настройка agent_recent_turns) реплик в prompt, *но возможно частично*.
    - Если follow-up = False: **не включаем ни summary, ни прошлые реплики** (полностью новая тема – чистый контекст).
    - Feature flag agent_memory_v2 контролирует использование этого механизма[17].
- **Fallback на новую цепочку:** Если есть хоть малейшее сомнение, считать вопрос новым (т.е. не follow-up). Это лучше, чем ложная связка.
- Правило: детектор должен быть смещён в сторону выдачи False (new topic) при неуверенности.
- Например, вопрос "Где применял RAG?" после обсуждения Python – формально, модель могла связать, но мы решаем: лучше начать заново, чем тащить 5 проектов Python. Это и делаем (в критериях видно, что хотим именно так)[70][71].
- Даже при follow-up = True, если предыдущий контекст слишком обширный и не тематический, лучше тоже сбросить. В backlog предлагалось правило: если предыдущий ответ был перечислением >5 разнородных фактов, то не использовать его целиком для уточнения[65]. Это можно зашить.
- В экстремальном случае можно задействовать LLM, чтобы переформулировать вопрос с учётом нужного контекста (refine question step)[72], но это усложнение, на первую итерацию избегаем.

**Ограничения и фичефлаги:** - AGENT_MEMORY_V2 флаг управляет новым поведением памяти[73]. Выключен – используется старый LangChain memory (которая, видимо, либо бесконечно хранит, либо использует checkpointing). - Нужно протестировать на многократных диалогах, что memory v2 не растёт бесконечно (summary ограничен AGENT_SUMMARY_MAX_CHARS)[69][68]. - Возможно, придётся отключить LangChain’s built-in memory if using custom. Если LangChain agent natively uses a memory, we replace it with our implementation or ensure it doesn't duplicate functionality. - Keep it simple: no external memory store, just ephemeral in session. This is fine for a single chat instance.

**Критерии приёмки:** - **Нет переноса нерелевантных фактов:** - Кейс из проблем: Пользователь: "Расскажи про опыт с Python." (Агент перечислил 5 проектов с Python). Следом пользователь: "Где применял RAG?" - Ожидаемый результат: агент трактует второй вопрос как новый (не связанный напрямую). Он не берет весь предыдущий список проектов. Вместо этого, по намерению RAG_USAGE выполняется поиск/граф, находит проекты с RAG. Ответ: перечисляет проекты с RAG (например, *AI-Portfolio* и *t2*), **не упоминая проекты из предыдущего ответа, где RAG не было**. - Приёмочный критерий: в ответе **отсутствует** проект СКИО и другие проекты из Python-списка, и отсутствуют фразы типа "других проектов с RAG нет" касающиеся Python-списка[61][74]. Ответ строго по теме RAG. Этот тест должен стабильно проходить. - Проверить на других потенциальных комбинациях: любые два последовательных вопроса на разные темы – второй должен рассматриваться независимо. Например: "Какие базы данных использовал?" (список техпроектов с БД) затем "Какие награды у тебя?" – второй вопрос вообще другой, memory v2 должна понять это и не лепить ничего про БД в ответ. - **Корректная работа follow-up:** - Кейс: Пользователь: "Расскажи про проект AI-Portfolio." (агент даёт детали проекта). Пользователь: "А какие там достижения?" - Ожидаем: второй вопрос распознан как follow-up, система понимает, что "там" = в AI-Portfolio. Выполняется либо граф-запрос достижений AI-Portfolio, либо поиск с фильтром по этому проекту. В итоге агент отвечает: "Достижения в проекте AI-Portfolio: - ... - ..." (список). Он **не спрашивает у пользователя уточнений, не перечисляет достижения других проектов**, только этого. - Критерий: ответ содержит именно достижения AI-Portfolio, все, и нигде не упоминается другой проект. - Другой: "Расскажи про проекты в EPAM." -> (список проектов EPAM) -> "А в Luxoft?" – здесь второй вопрос сменил сущность, но тоже короткий. Детектор увидит слово "Luxoft" – это явно новая сущность, пусть и продолжение темы "проекты". Вероятно, решит, что это **новый вопрос** (Intent тот же PROJECT_DETAILS, но Entity=Luxoft, != предыдущего). Скорее, лучше не считать follow-up, а как новый (он самодостаточный: "в Luxoft?" хотя начинается с "А", но есть явное слово). - Проверка: агент не тащит проекты EPAM лишние, а сразу отвечает про Luxoft. Если так – отлично. - **Summary ограничение:** - Провести длительный диалог (более 6-7 вопросов), убедиться, что summary обновляется и разговор не ухудшается. Например, поговорить последовательно о разных местах работы, сменить тему – проверить, что старые темы не всплывают. - Проверить, что summary не превышает лимит символов (например, задать много вопросов, потом вызвать /admin/stats или аналог для debug, если есть, или проверять в логах длину summary). - **Тестирование граничных случаев:** - Пользователь задал расплывчатый вопрос, агент ответил. Следующий вопрос непонятно, follow-up или нет (например: "О, интересно. И ещё, какую роль ты там играл?"). Допустим, первый был про проект, агент рассказал про команду. Второй: "какую роль ты там играл?" – очевидно про тот проект. Проверить, что детектор уловит "там" и привяжет. Ответ – "Я был тимлидом на проекте X". - Если детектор ошибётся (False вместо True или наоборот), оценить последствия: False-> агент просто ответит общо ("Где играл? Не понимаю"), True-> агент ответит, но если контекст неверный, может промахнуться. Стремимся минимизировать хужее из зол. - Такие кейсы тоже проиграть. Приёмка гибкая: команда вручную проверит на нескольких непредусмотренных диалогах, что поведение адекватное. - **Регрессия:** - Включение memory v2 не должно сломать обычный диалог. Если пользователь ведёт монолог с агентом (не сменяя тем), всё работает как раньше или лучше. - В частности, старый memory (LangChain) возможно позволял агенту ссылаться на прошлые ответы. Новый memory v2 должен делать то же, только аккуратней. Пример: - Пользователь: "Привет". Агент: "Привет, я AI-ассистент..." - Пользователь: "Как меня зовут?" (не по теме портфолио, но проверить) – агент *без памяти* не знает, с memory старым мог попытаться. Memory v2: anyway он не знает, скажет что-то. Главное, чтоб не сломался. - Follow-up "кто ты?" -> "а сколько тебе лет?" – не портфолио, но memory v2 все равно должна отработать (возможно, new topic, хотя логически follow-up, но нечего подставлять – может ответить "возраст не указан"). - **Настройки:** - Проверить, что agent_recent_turns и другие параметры влияют: например, если recent_turns=2, то при follow-up агент включает только последний QA. Если увеличить, включает больше. Для теста: установить 1 и задать follow-up – убедиться, что он не взял позапрошлый ответ. - agent_summary_trigger_turns: например, 5, проверить, что после 5 сообщений summary обновился/укоротился.

В итоге, приёмка эпика 5 считается успешной, если диалоговые тесты показывают отсутствие ранее отмеченных контекстных ошибок (особенно сценарий с RAG), и все genuine follow-ups продолжают работать (не вводя новых багов).

## Эпик 6 — Рефакторинг модулей и чистая архитектура

**Цели и обоснование:** Переработать кодовую базу rag-api-new в соответствии с принципами *Clean Architecture*, свести к минимуму технический долг. После внедрения всех новых функций структура должна оставаться понятной, расширяемой и поддерживаемой. Ключевые акценты: разделение ответственности (Single Responsibility), слабая связанность между модулями (зависимости через интерфейсы), отсутствие дублирования логики, возможность модульного тестирования каждого компонента. Сохранить целостность API (внешнее поведение не ломается), но улучшить внутреннюю организацию.

**Изменения по коду и архитектуре:** - **Разделение на слои:** Убедиться, что слои системы разграничены: - **Routing/Controller слой:** (app/main.py и роутеры) – только принимают запросы и вызывают соответствующие сервисы. - **Сервисный слой (Use cases):** rag модуль – здесь происходит бизнес-логика: формирование QueryPlan, обращение к хранилищам (Chroma, Graph), упаковка результатов. - **Модуль агента:** agent – orchestration для tool-LLM взаимодействия. Агент не должен знать деталей, как именно добываются данные – он вызывает инструмент через интерфейс. - **Data layer:** доступ к БД Chroma, возможно GraphDB или in-memory, а также внешним API (LLM). Они инстанциируются через deps.py (как было: там определены embeddings, chroma client и т.д.)[75][76]. Использовать эти зависимости, не создавать глобальных синглтонов внутри логики. - **Schemas/Models:** Pydantic-модели запросов/ответов и (внутренние) структуры вроде SearchResult – отделить от логики. - Иерархия папок уже в целом задана[77], новые файлы размещать согласно ей (QueryPlan, Entities, Context, Tools, Memory etc. по своим поддиректориям). - Принцип **Open-Closed:** добавление нового Intent или нового инструмента должно требовать минимальных изменений: например, добавить в enum Intent и прописать новый шаблон запроса в GraphSchema, вместо редактирования множества if/else.

- **SOLID применительно к новым компонентам:**
- **Single Responsibility:** каждый новый компонент имеет одну задачу:
    - GraphQueryTool: только получение данных из графа.
    - EntityRegistry: только хранение/поиск синонимов сущностей.
    - FollowUpDetector: только решение, follow-up или нет (не смешивается с memory хранением).
    - FormatRenderer: отвечает только за преобразование результата в текст (не лезет в логики поиска).
    - QueryPlanner: определение плана, не выполняет сам поиск.
- **Open/Closed:**
    - Использовать, например, перечисления или мэппинги вместо многочисленных условий. Например, можно завести словарь: INTENT_CONFIG = {ACHIEVEMENTS: {...}, ...}, содержащий параметры (allowed_types, tool, etc.). Тогда добавление Intent сводится к добавлению записи.
    - GraphSchema: если появится новый тип узла, он добавляется в схему и, например, query_tool поддержит новый Intent (можно расширять через полиморфизм или просто условия).
- **Interface Segregation & Dependency Inversion:**
    - Инструменты агента могут реализовать единый интерфейс Tool (возвр. dict), чтобы агент с ними работал абстрактно. В LangChain, вероятно, есть базовый Tool class – использовать его для graph_query_tool, portfolio_search_tool.
    - Подумать над интерфейсом к Graph: можно сделать абстракцию GraphRepository (с методами типа get_achievements(project_slug)) и иметь имплементацию, которая либо реальный graph DB, либо заглушка. Агент/инструмент зависит от интерфейса, а конкретную реализацию подсовываем через DI.
    - Так мы инвертируем зависимость: high-level код не зависит от деталей хранения графа.
    - В нашем случае, инъекцию можно сделать через FastAPI deps (как Chroma, LLM). Например, добавить GraphClient dependency (который внутри может использовать neo4j or networkx).
- **DRY:**
    - Удалить дубли: Например, если раньше был отдельный код поиска для /ask и для агента, теперь объединяем через portfolio_search(). Убедиться, что portfolio_search_tool вызывает ту же функцию, а не копирует логику.
    - Если в старой реализации были два разных механизма памяти (LangChain memory vs Memory v2), то при включении Memory v2 старый не используется. Можно со временем вообще отказаться от старого, но пока пусть остается под флагом.
    - Проверить, нет ли повторяющегося кода генерации prompt в разных местах – вынести в единый шаблонизатор.
    - Функции типа нормализации текста, обрезки по длине – если нужны и повторяются, вынести в utils.
- **Упрощение где возможно (KISS):**
- Избегать преждевременной оптимизации. Например, мы не вводим сразу сложный LLM-based followup или отдельный сервис графовой БД – сначала достаточно простого. Если увидим, что производительности хватает, так и оставить.
- Не раздувать количество классов без необходимости: если что-то можно решить функцией с понятным контрактом, не делать из этого класс с состоянием. (Но для тестируемости иногда классы удобнее; тут нужен баланс.)
- Документация в коде: писать понятные docstring'и для новых методов, чтобы не усложнять понимание.
- **Совместимость и модульность:**
- Все новые изменения контролируются фичефлагами[78]. Acceptance-тест требует, что при всех флагах = false, система работает точно как раньше[79]. Поэтому важно условные блоки аккуратно внедрить: например, if settings.RAG_ROUTER_V2: ... else: ....
- Конфигурация (модели, пороги) – оставить в settings.py[80], не захардкодивать. Добавить новые параметры (если нужны) по аналогии: e.g. GRAPH_RAG_ENABLE, MAX_LIST_ITEMS (если не было), etc.
- Не удалять сразу старые пути, пометить их как legacy. Например, portfolio_rag_tool остаётся, но в агент при новом флаге не используется[18]. Это на случай быстрого rollback.
- Разделить clearly: старые функции пометить комментарием "deprecated, use X" чтобы разработчики знали, куда смотреть для новой логики.

**Критерии приёмки:** - **Кодовая база:** - Обзор кода показывает, что каждая новая часть находится на своем месте, а не разбросана. Например, все, что касается Graph-RAG, либо в rag/graph.py (логика), agent/tools.py (интеграция) и rag/query_plan.py (выбор стратегии). В других местах лишь вызовы. Нет спутывания, что, скажем, внутри функции поиска внезапно формируются тексты ответа – это всё разнесено. - Сборка проекта без ошибок: python -m compileall -q services/rag-api-new/app проходит без ошибок синтаксиса[79]. - Прогонить имеющиеся unit-тесты (если они есть) – они должны проходить. Написать новые тесты для ключевых модулей и убедиться в их прохождении. - Линтер/статический анализ – код соответствует style guide, нет явных проблем. - Важное условие: **при отключенных фичах поведение не меняется**. Т.е. мы можем депLOYть с флагами off, всё стабильно. Это проверяется на staging: все основные функциональные тесты (включая интеграционные) дают идентичный результат старой версии. - **Процент покрытия тестами** желательно повысить, покрыв unit-тестами новые компоненты (QueryPlan, FollowUp, Format, Graph queries) – хотя бы до уровня ~80% на них.

- **Производительность и ресурсы:**
- Проверить, что добавление графового поиска не замедлило ответы значительно. Для простых запросов (которые идут через граф) ответ может даже ускориться, т.к. не надо делать длинный vector search. Для сложных – примерно то же.
- Memory v2: проверяем, что не растёт память процесса неконтролируемо при длинном диалоге (summary ограничен).
- Если используется внешняя БД (Chroma, plus maybe graph if we had chosen one), система по-прежнему укладывается в допустимые ресурсы.
- **Сценарные тесты end-to-end:** Выполнить финальный чек-лист (согласно Backlog регресс-чеклиста)[81]:
- привет – бот отвечает приветливо.
- кто ты – бот корректно представляется.
- где сейчас работает Дмитрий? – работает Intent CURRENT_JOB, ответ корректен (уже обсуждалось).
- какие достижения на проекте t2 / АЛОР / F3 / СКИО – для каждого из перечисленных проектов проверить ответ:
    - t2 (есть достижения) – все перечислены.
    - АЛОР (есть 3 достижения) – все 3 перечислены, ничего не потеряно.
    - F3 (допустим, есть достижения) – перечислены.
    - СКИО (если нет достижений, либо 1) – агент не придумывает лишнего, возможно скажет "по проекту СКИО отдельно достижений не выделено" или просто упомянет, что "СКИО – сам по себе проект по ...". Главное – консистентно. Если данных нет – кратко "нет отдельного списка достижений".
- какие языки программирования знает? – список языков (Python, C# etc., без лишнего).
- где применял RAG? – уже проверяли, должно быть без лишних.
- Кроме этого, многотуровые:
    - "Расскажи про опыт с Python." -> ... -> "а где применял RAG?" (нет лишнего)[82].
    - "Расскажи про проект X." -> ... -> "а там какие достижения?" (работает, все достижения X даны).
- Все эти сценарии должны отработать правильно при включённых новых фичах.
- Затем повторить несколько при фичах off – убедиться, что хоть ответы и хуже, но структура/формат такой же, как был (чтобы убедиться в fallback).
- **Документация и схемы:**
- В финале, обновить техническую документацию (в репозитории, видимо rag-api-new-doc.md) – описать новую архитектуру Graph-RAG, возможно приложить схему компонент.
- Для приемки можно предоставить схему данных: например, диаграмму узлов графа и их связей (Person->Company->Project->Achievement->Tech). Это подтвердит, что команда понимает модель.
- А также схему потоков: от вопроса -> IntentDetector -> QueryPlan -> либо GraphRepo либо VectorSearch -> FormatRenderer -> ответ.
- В тексте ТЗ эти моменты уже отражены, но для разработчиков и тестировщиков должна быть актуальная документация рядом с кодом.

Когда все перечисленные критерии удовлетворены и тесты пройдены, рефакторинг может считаться успешно завершённым. Сервис rag-api-new с Graph-RAG архитектурой будет выдавать ответы с полной и точной информацией, в удобном формате, сохраняя при этом стабильность и расширяемость системы. [83][84]

[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [16] [22] [23] [24] [26] [27] [28] [29] [34] [35] [41] [42] [43] [44] [45] [46] [47] [48] [49] [50] [56] [57] [58] [59] [60] [61] [62] [63] [64] [65] [70] [71] [72] [74] [83] [84] Текущие проблемы в ответах AI-агента.pdf

file://file_0000000055c871f4857fcebb4d9f1a8a

[14] [15] [17] [54] [75] [76] [77] [80] rag-api-new-doc.md

file://file_00000000c9e471f4b6a746f0254f86fa

[18] [19] [20] [21] [25] [30] [31] [32] [33] [36] [37] [38] [39] [40] [51] [52] [53] [55] [66] [67] [68] [69] [73] [78] [79] [81] [82] backlog.md

file://file_000000001e9c720ab8a3fc6e7088aba6
