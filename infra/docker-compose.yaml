version: "3.8"

services:
  # --- DB -------------------------------------------------------------
  postgres:
    image: postgres:16
    profiles: ["db"]
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5433:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./init/postgres-init.sql:/docker-entrypoint-initdb.d/00-init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 20
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  # --- Vector DB ------------------------------------------------------
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    profiles: ["rag"]
    restart: unless-stopped
    environment:
      CHROMA_SERVER_AUTH_ENABLED: "false"
    command: ["run", "--host", "0.0.0.0", "--port", "8000"]
    ports: ["8001:8000"]   # наружу 8001
    volumes:
      - chroma_data:/data
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/api/v1/heartbeat"]
      interval: 5s
      timeout: 3s
      retries: 30
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  # --- LLM ----------------------------------------------------------
  vllm:
    image: vllm/vllm-openai:latest
    profiles: ["ml"]
    restart: unless-stopped
    environment:
      VLLM_WORKER_USE_STDOUT: "1"
      HUGGING_FACE_HUB_TOKEN: ${HF_TOKEN}
    command: >
      --model meta-llama/Meta-Llama-3-8B-Instruct
      --max-num-batched-tokens 8192
      --download-dir /root/.cache/hf
      --host 0.0.0.0 --port 8000
    ports: ["8002:8000"]   # наружу 8002
    volumes:
      - hf_cache:/root/.cache/hf
    # Docker Desktop / Linux: включи GPU и оставь одну строку ниже
    gpus: all
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 30
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  # --- Content API ----------------------------------------------------
  content-api:
    build:
      context: ../services/content-api
      dockerfile: Dockerfile
    profiles: ["apps"]
    restart: unless-stopped
    environment:
      # внутри сети идём к postgres:5432
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      FRONTEND_ORIGIN: ${FRONTEND_ORIGIN}
    depends_on:
      postgres:
        condition: service_healthy
    ports: ["8003:8000"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 3s
      retries: 30
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  # --- RAG API --------------------------------------------------------
  rag-api:
    build:
      context: ../services/rag-api
      dockerfile: Dockerfile
    profiles: ["apps","rag"]
    restart: unless-stopped
    environment:
      OPENAI_BASE_URL: ${OPENAI_BASE_URL-http://vllm:8000}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL-text-embedding-3-small}
      RERANKER_MODEL: ${RERANKER_MODEL-}
      CHROMA_HOST: ${CHROMA_HOST-chroma}
      CHROMA_PORT: ${CHROMA_PORT-8000}
      FRONTEND_ORIGIN: ${FRONTEND_ORIGIN}
    depends_on:
      chroma:
        condition: service_healthy
      vllm:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports: ["8004:8000"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 3s
      retries: 30
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  # --- Frontend -------------------------------------------------------
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    profiles: ["apps"]
    restart: unless-stopped
    environment:
      NEXT_PUBLIC_RAG_API_URL: http://localhost:8004
      NEXT_PUBLIC_CONTENT_API_URL: http://localhost:8003
    depends_on:
      rag-api:
        condition: service_started
      content-api:
        condition: service_started
    ports: ["3000:3000"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:3000"]
      interval: 10s
      timeout: 5s
      retries: 30
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

volumes:
  pg_data:
  chroma_data:
  hf_cache:
